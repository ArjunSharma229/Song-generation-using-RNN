{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "882e06b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import music21 as m21\n",
    "import numpy as np\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8dd5347",
   "metadata": {},
   "outputs": [],
   "source": [
    "KERN_DATASET_PATH = \"deutschl/erk\"\n",
    "SAVE_DIR = \"dataset\"\n",
    "SINGLE_FILE_DATASET = \"file_dataset\"\n",
    "MAPPING_PATH = \"mapping.json\"\n",
    "SEQUENCE_LENGTH = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f36968a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCEPTABLE_DURATIONS = [\n",
    "    0.25,\n",
    "    0.5,\n",
    "    0.75,\n",
    "    1.0,\n",
    "    1.5,\n",
    "    2,\n",
    "    3,\n",
    "    4\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37db24a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_songs_in_kern(dataset_path):\n",
    "\n",
    "    songs = []\n",
    "\n",
    "    for path, subdirs, files in os.walk(dataset_path):\n",
    "        for file in files:\n",
    "\n",
    "            if file[-3:] == \"krn\":\n",
    "                song = m21.converter.parse(os.path.join(path, file))\n",
    "                songs.append(song)\n",
    "    return songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f52b9a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_acceptable_durations(song, acceptable_durations):\n",
    "\n",
    "    for note in song.flat.notesAndRests:\n",
    "        if note.duration.quarterLength not in acceptable_durations:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51f85bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transpose(song):\n",
    "\n",
    "    \n",
    "    parts = song.getElementsByClass(m21.stream.Part)\n",
    "    measures_part0 = parts[0].getElementsByClass(m21.stream.Measure)\n",
    "    key = measures_part0[0][4]\n",
    "\n",
    "    \n",
    "    if not isinstance(key, m21.key.Key):\n",
    "        key = song.analyze(\"key\")\n",
    "\n",
    "    \n",
    "    if key.mode == \"major\":\n",
    "        interval = m21.interval.Interval(key.tonic, m21.pitch.Pitch(\"C\"))\n",
    "    elif key.mode == \"minor\":\n",
    "        interval = m21.interval.Interval(key.tonic, m21.pitch.Pitch(\"A\"))\n",
    "\n",
    "    # transpose song by calculated interval\n",
    "    tranposed_song = song.transpose(interval)\n",
    "    return tranposed_song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b9bc4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_song(song, time_step=0.25):\n",
    "\n",
    "    encoded_song = []\n",
    "\n",
    "    for event in song.flat.notesAndRests:\n",
    "\n",
    "        # handle notes\n",
    "        if isinstance(event, m21.note.Note):\n",
    "            symbol = event.pitch.midi # 60\n",
    "        # handle rests\n",
    "        elif isinstance(event, m21.note.Rest):\n",
    "            symbol = \"r\"\n",
    "\n",
    "        # convert the note/rest into time series notation\n",
    "        steps = int(event.duration.quarterLength / time_step)\n",
    "        for step in range(steps):\n",
    "\n",
    "            if step == 0:\n",
    "                encoded_song.append(symbol)\n",
    "            else:\n",
    "                encoded_song.append(\"_\")\n",
    "\n",
    "    # cast encoded song to str\n",
    "    encoded_song = \" \".join(map(str, encoded_song))\n",
    "\n",
    "    return encoded_song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92a04da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(dataset_path):\n",
    "\n",
    "    # load folk songs\n",
    "    print(\"Loading songs...\")\n",
    "    songs = load_songs_in_kern(dataset_path)\n",
    "    print(f\"Loaded {len(songs)} songs.\")\n",
    "\n",
    "    for i, song in enumerate(songs):\n",
    "\n",
    "        # filter out songs that have non-acceptable durations\n",
    "        if not has_acceptable_durations(song, ACCEPTABLE_DURATIONS):\n",
    "            continue\n",
    "\n",
    "        # transpose songs to Cmaj/Amin\n",
    "        song = transpose(song)\n",
    "\n",
    "        # encode songs with music time series representation\n",
    "        encoded_song = encode_song(song)\n",
    "\n",
    "        # save songs to text file\n",
    "        save_path = os.path.join(SAVE_DIR, str(i))\n",
    "        with open(save_path, \"w\") as fp:\n",
    "            fp.write(encoded_song)\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Song {i} out of {len(songs)} processed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d52201b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(file_path):\n",
    "    with open(file_path, \"r\") as fp:\n",
    "        song = fp.read()\n",
    "    return song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "597e805a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_single_file_dataset(dataset_path, file_dataset_path, sequence_length):\n",
    "\n",
    "    new_song_delimiter = \"/ \" * sequence_length\n",
    "    songs = \"\"\n",
    "\n",
    "    # load encoded songs and add delimiters\n",
    "    for path, _, files in os.walk(dataset_path):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(path, file)\n",
    "            song = load(file_path)\n",
    "            songs = songs + song + \" \" + new_song_delimiter\n",
    "\n",
    "    # remove empty space from last character of string\n",
    "    songs = songs[:-1]\n",
    "\n",
    "    # save string that contains all the dataset\n",
    "    with open(file_dataset_path, \"w\") as fp:\n",
    "        fp.write(songs)\n",
    "\n",
    "    return songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdaeb747",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mapping(songs, mapping_path):\n",
    "    mappings = {}\n",
    "\n",
    "    # identify the vocabulary\n",
    "    songs = songs.split()\n",
    "    vocabulary = list(set(songs))\n",
    "\n",
    "    # create mappings\n",
    "    for i, symbol in enumerate(vocabulary):\n",
    "        mappings[symbol] = i\n",
    "\n",
    "    # save voabulary to a json file\n",
    "    with open(mapping_path, \"w\") as fp:\n",
    "        json.dump(mappings, fp, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f70736ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_songs_to_int(songs):\n",
    "    int_songs = []\n",
    "\n",
    "    # load mappings\n",
    "    with open(MAPPING_PATH, \"r\") as fp:\n",
    "        mappings = json.load(fp)\n",
    "\n",
    "    # transform songs string to list\n",
    "    songs = songs.split()\n",
    "\n",
    "    # map songs to int\n",
    "    for symbol in songs:\n",
    "        int_songs.append(mappings[symbol])\n",
    "\n",
    "    return int_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7cf7a211",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_sequences(sequence_length):\n",
    "\n",
    "    # load songs and map them to int\n",
    "    songs = load(SINGLE_FILE_DATASET)\n",
    "    int_songs = convert_songs_to_int(songs)\n",
    "\n",
    "    inputs = []\n",
    "    targets = []\n",
    "\n",
    "    # generate the training sequences\n",
    "    num_sequences = len(int_songs) - sequence_length\n",
    "    for i in range(num_sequences):\n",
    "        inputs.append(int_songs[i:i+sequence_length])\n",
    "        targets.append(int_songs[i+sequence_length])\n",
    "\n",
    "    # one-hot encode the sequences\n",
    "    vocabulary_size = len(set(int_songs))\n",
    "    # inputs size: (# of sequences, sequence length, vocabulary size)\n",
    "    inputs = keras.utils.to_categorical(inputs, num_classes=vocabulary_size)\n",
    "    targets = np.array(targets)\n",
    "    return inputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff2b5acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    preprocess(KERN_DATASET_PATH)\n",
    "    songs = create_single_file_dataset(SAVE_DIR, SINGLE_FILE_DATASET, SEQUENCE_LENGTH)\n",
    "    create_mapping(songs, MAPPING_PATH)\n",
    "    inputs, targets = generate_training_sequences(SEQUENCE_LENGTH)\n",
    "    a=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "927cb127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading songs...\n",
      "Loaded 1700 songs.\n",
      "Song 0 out of 1700 processed\n",
      "Song 10 out of 1700 processed\n",
      "Song 20 out of 1700 processed\n",
      "Song 30 out of 1700 processed\n",
      "Song 40 out of 1700 processed\n",
      "Song 50 out of 1700 processed\n",
      "Song 60 out of 1700 processed\n",
      "Song 70 out of 1700 processed\n",
      "Song 80 out of 1700 processed\n",
      "Song 90 out of 1700 processed\n",
      "Song 100 out of 1700 processed\n",
      "Song 110 out of 1700 processed\n",
      "Song 120 out of 1700 processed\n",
      "Song 130 out of 1700 processed\n",
      "Song 140 out of 1700 processed\n",
      "Song 150 out of 1700 processed\n",
      "Song 160 out of 1700 processed\n",
      "Song 170 out of 1700 processed\n",
      "Song 180 out of 1700 processed\n",
      "Song 190 out of 1700 processed\n",
      "Song 200 out of 1700 processed\n",
      "Song 210 out of 1700 processed\n",
      "Song 220 out of 1700 processed\n",
      "Song 230 out of 1700 processed\n",
      "Song 240 out of 1700 processed\n",
      "Song 250 out of 1700 processed\n",
      "Song 260 out of 1700 processed\n",
      "Song 270 out of 1700 processed\n",
      "Song 280 out of 1700 processed\n",
      "Song 290 out of 1700 processed\n",
      "Song 300 out of 1700 processed\n",
      "Song 310 out of 1700 processed\n",
      "Song 320 out of 1700 processed\n",
      "Song 330 out of 1700 processed\n",
      "Song 340 out of 1700 processed\n",
      "Song 350 out of 1700 processed\n",
      "Song 360 out of 1700 processed\n",
      "Song 370 out of 1700 processed\n",
      "Song 380 out of 1700 processed\n",
      "Song 390 out of 1700 processed\n",
      "Song 400 out of 1700 processed\n",
      "Song 410 out of 1700 processed\n",
      "Song 420 out of 1700 processed\n",
      "Song 430 out of 1700 processed\n",
      "Song 440 out of 1700 processed\n",
      "Song 450 out of 1700 processed\n",
      "Song 460 out of 1700 processed\n",
      "Song 470 out of 1700 processed\n",
      "Song 480 out of 1700 processed\n",
      "Song 490 out of 1700 processed\n",
      "Song 500 out of 1700 processed\n",
      "Song 510 out of 1700 processed\n",
      "Song 520 out of 1700 processed\n",
      "Song 530 out of 1700 processed\n",
      "Song 540 out of 1700 processed\n",
      "Song 550 out of 1700 processed\n",
      "Song 560 out of 1700 processed\n",
      "Song 570 out of 1700 processed\n",
      "Song 580 out of 1700 processed\n",
      "Song 590 out of 1700 processed\n",
      "Song 600 out of 1700 processed\n",
      "Song 610 out of 1700 processed\n",
      "Song 620 out of 1700 processed\n",
      "Song 630 out of 1700 processed\n",
      "Song 640 out of 1700 processed\n",
      "Song 650 out of 1700 processed\n",
      "Song 660 out of 1700 processed\n",
      "Song 670 out of 1700 processed\n",
      "Song 680 out of 1700 processed\n",
      "Song 690 out of 1700 processed\n",
      "Song 700 out of 1700 processed\n",
      "Song 710 out of 1700 processed\n",
      "Song 720 out of 1700 processed\n",
      "Song 730 out of 1700 processed\n",
      "Song 740 out of 1700 processed\n",
      "Song 750 out of 1700 processed\n",
      "Song 760 out of 1700 processed\n",
      "Song 770 out of 1700 processed\n",
      "Song 780 out of 1700 processed\n",
      "Song 790 out of 1700 processed\n",
      "Song 800 out of 1700 processed\n",
      "Song 810 out of 1700 processed\n",
      "Song 820 out of 1700 processed\n",
      "Song 830 out of 1700 processed\n",
      "Song 840 out of 1700 processed\n",
      "Song 850 out of 1700 processed\n",
      "Song 860 out of 1700 processed\n",
      "Song 870 out of 1700 processed\n",
      "Song 880 out of 1700 processed\n",
      "Song 890 out of 1700 processed\n",
      "Song 900 out of 1700 processed\n",
      "Song 910 out of 1700 processed\n",
      "Song 920 out of 1700 processed\n",
      "Song 930 out of 1700 processed\n",
      "Song 940 out of 1700 processed\n",
      "Song 950 out of 1700 processed\n",
      "Song 960 out of 1700 processed\n",
      "Song 970 out of 1700 processed\n",
      "Song 980 out of 1700 processed\n",
      "Song 990 out of 1700 processed\n",
      "Song 1000 out of 1700 processed\n",
      "Song 1010 out of 1700 processed\n",
      "Song 1020 out of 1700 processed\n",
      "Song 1030 out of 1700 processed\n",
      "Song 1040 out of 1700 processed\n",
      "Song 1050 out of 1700 processed\n",
      "Song 1060 out of 1700 processed\n",
      "Song 1070 out of 1700 processed\n",
      "Song 1080 out of 1700 processed\n",
      "Song 1090 out of 1700 processed\n",
      "Song 1100 out of 1700 processed\n",
      "Song 1110 out of 1700 processed\n",
      "Song 1120 out of 1700 processed\n",
      "Song 1130 out of 1700 processed\n",
      "Song 1140 out of 1700 processed\n",
      "Song 1150 out of 1700 processed\n",
      "Song 1160 out of 1700 processed\n",
      "Song 1170 out of 1700 processed\n",
      "Song 1180 out of 1700 processed\n",
      "Song 1190 out of 1700 processed\n",
      "Song 1200 out of 1700 processed\n",
      "Song 1210 out of 1700 processed\n",
      "Song 1220 out of 1700 processed\n",
      "Song 1230 out of 1700 processed\n",
      "Song 1240 out of 1700 processed\n",
      "Song 1250 out of 1700 processed\n",
      "Song 1260 out of 1700 processed\n",
      "Song 1270 out of 1700 processed\n",
      "Song 1280 out of 1700 processed\n",
      "Song 1290 out of 1700 processed\n",
      "Song 1300 out of 1700 processed\n",
      "Song 1310 out of 1700 processed\n",
      "Song 1320 out of 1700 processed\n",
      "Song 1330 out of 1700 processed\n",
      "Song 1340 out of 1700 processed\n",
      "Song 1350 out of 1700 processed\n",
      "Song 1360 out of 1700 processed\n",
      "Song 1370 out of 1700 processed\n",
      "Song 1380 out of 1700 processed\n",
      "Song 1390 out of 1700 processed\n",
      "Song 1400 out of 1700 processed\n",
      "Song 1410 out of 1700 processed\n",
      "Song 1420 out of 1700 processed\n",
      "Song 1430 out of 1700 processed\n",
      "Song 1440 out of 1700 processed\n",
      "Song 1450 out of 1700 processed\n",
      "Song 1460 out of 1700 processed\n",
      "Song 1470 out of 1700 processed\n",
      "Song 1480 out of 1700 processed\n",
      "Song 1490 out of 1700 processed\n",
      "Song 1500 out of 1700 processed\n",
      "Song 1510 out of 1700 processed\n",
      "Song 1520 out of 1700 processed\n",
      "Song 1530 out of 1700 processed\n",
      "Song 1540 out of 1700 processed\n",
      "Song 1550 out of 1700 processed\n",
      "Song 1560 out of 1700 processed\n",
      "Song 1570 out of 1700 processed\n",
      "Song 1590 out of 1700 processed\n",
      "Song 1600 out of 1700 processed\n",
      "Song 1610 out of 1700 processed\n",
      "Song 1620 out of 1700 processed\n",
      "Song 1630 out of 1700 processed\n",
      "Song 1640 out of 1700 processed\n",
      "Song 1650 out of 1700 processed\n",
      "Song 1660 out of 1700 processed\n",
      "Song 1670 out of 1700 processed\n",
      "Song 1680 out of 1700 processed\n",
      "Song 1690 out of 1700 processed\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153e9cec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
